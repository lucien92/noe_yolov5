{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"2pMcPEIkmnVU"},"source":["<h1> Classification lepidoptères</h1>\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15008,"status":"ok","timestamp":1658840260371,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MorcXQTb22HG","outputId":"997a4015-4e21-4ce9-d9a7-6af7ba61c808"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xzZYwhV0Iaww"},"source":["## Téléchargement de la base de données"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1658842417221,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"7AoxedDPm5Bu"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import preprocessing\n","from tensorflow.keras.preprocessing import image_dataset_from_directory"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1046,"status":"ok","timestamp":1658842418749,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"I7Di5BLCIh-_","outputId":"7dd95317-c6ba-4442-961c-a457133d7d49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19289 files belonging to 122 classes.\n"]}],"source":["IMG_SIZE = 224\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/train',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=8,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","#on veut afficher le nombre de fichier trouvé dans train_ds\n","nb_train = len(train_ds.file_paths)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1658842418750,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"VgrOKSfaIh-_","outputId":"b2d52dcc-a61e-49cd-c35b-8538f58c17bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Acasis viretata', 'Acleris holmiana', 'Acleris variegana', 'Acontia lucida', 'Agapeta hamana', 'Agapeta zoegana', 'Agrotis exclamationis', 'Agrotis puta', 'Aleimma loeflingiana', 'Anania hortulata', 'Angerona prunaria', 'Apamea crenata', 'Aphomia sociella', 'Aplocera plagiata', 'Apoda limacodes', 'Archips xylosteana', 'Arctia villica', 'Atethmia centrago', 'Biston betularia', 'Campaea margaritaria', 'Camptogramma bilineata', 'Carcina quercana', 'Celypha striana', 'Chiasmia clathrata', 'Chrysoteuchia culmella', 'Colocasia coryli', 'Cosmia trapezina', 'Crambus lathoniellus', 'Crambus pascuella', 'Craniophora ligustri', 'Cryphia algae', 'Cyclophora punctaria', 'Cydalima perspectalis', 'Dolicharthria punctalis', 'Dysgonia algira', 'Ecleora solieraria', 'Ecpyrrhorrhoe rubiginalis', 'Eilema caniola', 'Eilema complana', 'Eilema griseola', 'Eilema lurideola', 'Endotricha flammealis', 'Ennomos erosaria', 'Epiblema foenella', 'Epirrhoe alternata', 'Epirrhoe galiata', 'Eremobia ochroleuca', 'Ethmia bipunctella', 'Eublemma parva', 'Eucrostes indigenata', 'Eudonia lacustrata', 'Eudonia mercurella', 'Eupithecia centaureata', 'Euproctis chrysorrhoea', 'Euthrix potatoria', 'Euxoa obelisca', 'Evergestis forficalis', 'Falcaria lacertinaria', 'Gastropacha quercifolia', 'Habrosyne pyritoides', 'Homoeosoma sinuella', 'Hoplodrina octogenaria', 'Horisme vitalbata', 'Hypena proboscidalis', 'Hypsopygia costalis', 'Idaea aversata', 'Idaea degeneraria', 'Idaea filicata', 'Idaea fuscovenosa', 'Idaea humiliata', 'Idaea infirmaria', 'Idaea moniliata', 'Idaea ostrinaria', 'Idaea rusticata', 'Idaea subsericeata', 'Laspeyria flexula', 'Ligdia adustata', 'Lomaspilis marginata', 'Lozotaeniodes formosana', 'Lymantria dispar', 'Malacosoma neustria', 'Mesoligia furuncula', 'Mythimna albipuncta', 'Mythimna vitellina', 'Nomophila noctuella', 'Nycteola revayana', 'Ochropleura plecta', 'Oncocera semirubella', 'Orthonama obstipata', 'Ostrinia nubilalis', 'Parapoynx stratiotata', 'Pelurga comitata', 'Peribatodes rhomboidaria', 'Phycita roborella', 'Plutella xylostella', 'Pyrausta aurata', 'Pyrausta despicata', 'Pyrausta purpuralis', 'Pyrausta sanguinalis', 'Rhodometra sacraria', 'Rivula sericealis', 'Scoparia pyralella', 'Scoparia subfusca', 'Scopula ornata', 'Scopula rubiginata', 'Sitochroa verticalis', 'Sphinx ligustri', 'Spilonota ocellana', 'Stauropus fagi', 'Stegania trimaculata', 'Synaphe punctalis', 'Thalpophila matura', 'Thaumetopoea processionea', 'Thisanotia chrysonuchella', 'Thyatira batis', 'Timandra comae', 'Tortrix viridana', 'Triodia sylvina', 'Tyta luctuosa', 'Watsonalla uncinula', 'Xestia c-nigrum', 'Zeiraphera isertana']\n","122\n"]}],"source":["class_names = train_ds.class_names\n","print(class_names)\n","nb_classes = len(class_names)\n","print(nb_classes)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"T8wS3HAynMlY"},"source":["## Chargement des données"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1658842446314,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"FR4iw29DI1V_"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1658842446586,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"4jXjNBybI1V_"},"outputs":[],"source":["# Paramètres\n","IMG_SIZE = 224 # pour utiliser ResNet"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1658842447622,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"I_nea1RwI1V_","outputId":"8ca05ddc-6308-47e6-91c2-d82cb8ca9ebe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19289 files belonging to 122 classes.\n","Found 2393 files belonging to 122 classes.\n"]}],"source":["# Récupération des dataset pour l'entraînement (train, val)\n","# Shuffle à false pour avoir accès aux images depuis\n","# leur chemin d'accès avec train_ds.file_paths\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/train/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","\n","validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/val/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","nb_val = len(validation_ds.file_paths)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CN1hk3SeoEYJ"},"source":["## Augmentation de données : Sequence et Albumentations"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"executionInfo":{"elapsed":22321,"status":"ok","timestamp":1658842474363,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"-WvZXN580RYP","outputId":"c774cb1e-156d-48a6-e6f6-97bcc6c0b2ab"},"outputs":[],"source":["# !pip uninstall opencv-python-headless==4.5.5.62\n","# !pip install opencv-python-headless==4.1.2.30\n","# !pip install -q -U albumentations\n","# !echo \"$(pip freeze | grep albumentations) is successfully installed\""]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1658842520255,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"G1H0ApCB35Gn"},"outputs":[],"source":["from albumentations import (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n","import albumentations as A\n","\n","AUGMENTATIONS_TRAIN = Compose([\n","    Rotate(limit=[0,100], p=0.5),\n","    HorizontalFlip(p=0.5),\n","    VerticalFlip(p=0.5),\n","    Affine(shear=[-45, 45], p=0.5),\n","    RandomBrightnessContrast(p=0.5)\n","])"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1658842630318,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tEaycO8VhyLH"},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import cv2 as cv\n","\n","class AbeillesSequence(Sequence):\n","    # Initialisation de la séquence avec différents paramètres\n","    def __init__(self, x_train, y_train, batch_size, augmentations):\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.classes = class_names\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.indices1 = np.arange(len(x_train))\n","        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n","        # aux données et sont randomisés à chaque epoch pour varier la composition\n","        # des batches au cours de l'entraînement\n","\n","    # Fonction calculant le nombre de pas de descente du gradient par epoch\n","    def __len__(self):\n","        return int(np.ceil(self.x_train.shape[0] / float(self.batch_size)))\n","    \n","    # Application de l'augmentation de données à chaque image du batch\n","    def apply_augmentation(self, bx, by):\n","\n","        batch_x = np.zeros((bx.shape[0], IMG_SIZE, IMG_SIZE, 3))\n","        batch_y = by\n","        \n","        # Pour chaque image du batch\n","        for i in range(len(bx)):\n","            class_labels = []\n","            class_id = np.argmax(by[i])\n","            class_labels.append(self.classes[class_id])\n","\n","            # Application de l'augmentation à l'image\n","            img = cv.imread(bx[i])\n","            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","            transformed = self.augment(image=img)\n","            #on veut changer la taille de transformed['image'] en (224,224,3)\n","            transformed_image = transformed['image'].copy()\n","            transformed_image.resize((IMG_SIZE, IMG_SIZE, 3))\n","\n","            batch_x[i] = transformed_image\n","      \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n","    # idx = position du batch (idx = 5 => on prend le 5ème batch)\n","    def __getitem__(self, idx):\n","        batch_x = self.x_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","        batch_y = self.y_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","           \n","        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n","\n","        # Normalisation des données\n","        batch_x = tf.keras.applications.resnet.preprocess_input(batch_x)\n","        \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices1)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":12892,"status":"ok","timestamp":1658842645801,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MQxHTeedPwsn"},"outputs":[{"name":"stdout","output_type":"stream","text":["122\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-19 13:52:41.849169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [19289]\n","\t [[{{node Placeholder/_4}}]]\n","2023-05-19 13:52:41.849471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [19289]\n","\t [[{{node Placeholder/_4}}]]\n"]}],"source":["# Les images sont stockées avec les chemins d'accès\n","import numpy as np\n","print(nb_classes)\n","\n","x_train = np.array(train_ds.file_paths)\n","y_train = np.zeros((nb_train, nb_classes))#rentrer la taille du train: 19789\n","\n","ind_data = 0\n","for bx, by in train_ds.as_numpy_iterator():\n","  y_train[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":3795,"status":"ok","timestamp":1658842649588,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"qclVcaJrG1Gn"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-19 13:52:49.245272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2393]\n","\t [[{{node Placeholder/_0}}]]\n","2023-05-19 13:52:49.245642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2393]\n","\t [[{{node Placeholder/_0}}]]\n"]}],"source":["# Instanciation de la Sequence\n","train_ds_aug = AbeillesSequence(x_train, y_train, batch_size=16, augmentations=AUGMENTATIONS_TRAIN)\n","\n","# Normalisation des données de validation\n","import numpy as np\n","import tensorflow as tf\n","\n","x_val = np.zeros((nb_val, IMG_SIZE, IMG_SIZE, 3))#rentrer la taille du valval\n","y_val = np.zeros((nb_val, nb_classes))#rentrer la taille du val\n","\n","ind_data = 0\n","for bx, by in validation_ds.as_numpy_iterator():\n","  x_val[ind_data:ind_data+bx.shape[0]] = bx\n","  y_val[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]\n","\n","x_val = tf.keras.applications.resnet.preprocess_input(x_val)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"h6MijFSSqNEi"},"source":["## Création du modèle"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1658842655320,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"vw8pjRnlGcOW"},"outputs":[],"source":["from tensorflow.keras import regularizers\n","from tensorflow.keras import optimizers\n","import tensorflow as tf"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wHrwHiS3Szq3"},"source":["### Poids d'imagenet"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":4453,"status":"ok","timestamp":1658842661739,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"cVEsReLqsmGX"},"outputs":[],"source":["conv_base = keras.applications.resnet.ResNet50(\n","    include_top=False,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    pooling=None,\n","    classes=nb_classes,\n",")\n","\n","model = keras.Sequential(\n","    [\n","        conv_base,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","    ]\n",")"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1658842661740,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"8Ouz5O07S8q3","outputId":"b8c82afd-4776-4006-fe62-07a652e7bfde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_1 (Dense)             (None, 122)               249978    \n","                                                                 \n","=================================================================\n","Total params: 23,837,690\n","Trainable params: 23,784,570\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"34MnJ8YHqXKC"},"source":["### Poids INat2021"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5731,"status":"ok","timestamp":1658475118412,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"LR4GIHqVqXKC","outputId":"984ac58b-baa3-4228-876f-42bfb539af62"},"outputs":[],"source":["# from tensorflow import keras\n","# conv_base = keras.models.load_model('drive/MyDrive/Stage2A/INat2021/2623871_resnet50_simclr_v1_inat20_no_top.h5')\n","\n","# model = keras.Sequential(\n","#     [\n","#         conv_base,\n","#         layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","#     ]\n","# )"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1658475126907,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"w5wZDTlHqXKD","outputId":"bc14d7c3-074d-45d0-b798-bd78536f4ab1"},"outputs":[],"source":["# model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HYD4k8GDtG-G"},"source":["## Hierarchical loss"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":852,"status":"ok","timestamp":1658842675647,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"vHFsiNjctJsM"},"outputs":[{"name":"stdout","output_type":"stream","text":["nb species:  122\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","hierarchie = pd.read_csv(\"/Workspace/Repos/b00786574@essec.edu/noe_yolov5/classif/convert_and_analyse_data/correct_list.csv\", delimiter = ';')\n","\n","species = hierarchie[\"Espece\"].unique()\n","nb_species = len(species)\n","\n","genus = list(hierarchie[\"Genre\"].unique())\n","nb_genus = len(genus)\n","\n","family = list(hierarchie[\"Famille\"].unique())\n","nb_family = len(family)\n","\n","subfamily = list(hierarchie[\"Sous-Famille\"].unique())\n","nb_subfamily = len(subfamily)\n","\n","#hierarchie.set_index(\"species\", inplace=True)\n","data = pd.read_csv(\"/Workspace/Repos/b00786574@essec.edu/noe_yolov5/classif/convert_and_analyse_data/especes.csv\")\n","#data.set_index(\"species\", inplace=True)\n","\n","species_to_genus = np.zeros((nb_genus, nb_species))\n","genus_to_subfamily = np.zeros((nb_subfamily, nb_genus))\n","subfamily_to_family = np.zeros((nb_family, nb_subfamily))\n","print(\"nb species: \", nb_species)\n","for i in range(nb_species):\n","  print(i)\n","  nb_images = data.at[i, \"0\"]\n","  # species -> genus\n","  genus_species = hierarchie.at[i, \"Genre\"]\n","  ind_genus = genus.index(genus_species)\n","  species_to_genus[ind_genus, i] = 1\n","\n","  # genus -> subfamily\n","  subfamily_species = hierarchie.at[i, \"Sous-Famille\"]\n","  ind_subfamily = subfamily.index(subfamily_species)\n","  genus_to_subfamily[ind_subfamily, ind_genus] = 1\n","\n","  # subfamily -> family\n","  family_species = hierarchie.at[i, \"Famille\"]\n","  ind_family = family.index(family_species)\n","  subfamily_to_family[ind_family, ind_subfamily] = 1"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658842675648,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tAmdf0ELtSUr"},"outputs":[],"source":["from numpy.ma.core import transpose\n","from keras import backend as K\n","import math\n","import tensorflow as tf\n","\n","# Définition de la fonction de perte\n","def Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size, alpha=0.1):\n","\n","    def weight(height=1):\n","      return math.exp(-alpha * height)\n","    \n","    def species_loss(y_true, y_pred):\n","      height = 0\n","      return weight(height) * K.categorical_crossentropy(y_true, y_pred)\n","  \n","    def species_to_genus_loss(y_true, y_pred):\n","      height = 1\n","      y_true_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_true, tf.float64), transpose_b=True))\n","      y_pred_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_pred, tf.float64), transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_genus, y_pred_genus), y_true_genus, y_pred_genus\n","    \n","    def genus_to_subfamily_loss(y_true, y_pred):\n","      height = 2\n","      y_true_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_true, transpose_b=True))\n","      y_pred_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_subfamily, y_pred_subfamily), y_true_subfamily, y_pred_subfamily\n","    \n","    def subfamily_to_family_loss(y_true, y_pred):\n","      height = 3\n","      y_true_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_true, transpose_b=True))\n","      y_pred_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_family, y_pred_family)\n","\n","    def HIERARCHICAL_loss(y_true, y_pred):\n","      loss_species = tf.cast(species_loss(y_true, y_pred), tf.float64)\n","      loss_genus, y_true_genus, y_pred_genus = species_to_genus_loss(y_true, y_pred)\n","      loss_subfamily, y_true_subfamily, y_pred_subfamily = genus_to_subfamily_loss(y_true_genus, y_pred_genus)\n","      loss_family = subfamily_to_family_loss(y_true_subfamily, y_pred_subfamily)\n","      return (loss_species + loss_genus + loss_subfamily + loss_family)/batch_size\n","   \n","    # Return a function\n","    return HIERARCHICAL_loss"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658842675649,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MEDUO4smtiAS"},"outputs":[],"source":["loss=[Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size=16, alpha=0.5)]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AGrRfh4ZrHM1"},"source":["## Entraînement du modèle"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1658842682265,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"IOxq6KpzGb9I"},"outputs":[],"source":["# Ajout de l'optimiseur, de la fonction coût et des métriques\n","lr = 1e-3\n","model.compile(optimizers.SGD(learning_rate=lr, momentum=0.9), loss=loss, metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658842683474,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tWhbz7V0Gtjs"},"outputs":[],"source":["# Les callbacks, là où on sauvegarde les poids du réseau\n","\n","#filepath = path to save the model at the end of each epoch\n","\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/Workspace/Repos/b00786574@essec.edu/noe_yolov5/classif/convert_and_analyse_data/model_crop/model_crop', \n","    save_weights_only=True,\n","    monitor='val_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1)\n","\n","#early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","#    monitor=\"val_categorical_accuracy\",\n","#    min_delta=0.01,\n","#    patience=8,\n","#    verbose=1,\n","#    mode=\"auto\")\n","reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1,\n","                              patience=5, min_lr=0.00001, verbose=1)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":129103,"status":"error","timestamp":1658842814895,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"0hxLaoBeGxTn","outputId":"c04250de-bd71-4292-8434-629bf8ae1fa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/80\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-19 13:52:53.658990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n","\t [[{{node Placeholder/_0}}]]\n","2023-05-19 13:53:02.782440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n","2023-05-19 13:53:05.745052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","2023-05-19 13:53:05.793115: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5dfd336160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-05-19 13:53:05.793135: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n","2023-05-19 13:53:06.048415: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["1206/1206 [==============================] - ETA: 0s - loss: 0.6086 - categorical_accuracy: 0.0101 - precision: 0.0000e+00 - recall: 0.0000e+00"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["history = model.fit(train_ds_aug, epochs=80, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb]) #nbre d'epoch de fabio:150"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWAJ28hjh3VB4RHipSfk+k","collapsed_sections":["xzZYwhV0Iaww","T8wS3HAynMlY","CN1hk3SeoEYJ","h6MijFSSqNEi","wHrwHiS3Szq3","34MnJ8YHqXKC","HYD4k8GDtG-G","AGrRfh4ZrHM1"],"name":"ClassifAbeilles.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
