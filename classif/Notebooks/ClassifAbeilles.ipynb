{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"2pMcPEIkmnVU"},"source":["<h1> Classification lepidoptères</h1>\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15008,"status":"ok","timestamp":1658840260371,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MorcXQTb22HG","outputId":"997a4015-4e21-4ce9-d9a7-6af7ba61c808"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"xzZYwhV0Iaww"},"source":["## Téléchargement de la base de données"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1658842417221,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"7AoxedDPm5Bu"},"outputs":[{"ename":"AttributeError","evalue":"module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/__init__.py:476\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    475\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m    477\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[39mpass\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/mixed_precision/loss_scale_optimizer.py:1180\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39m_create_or_restore_slot_variable(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m         slot_variable_position, slot_name, variable)\n\u001b[1;32m   1179\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1180\u001b[0m mixed_precision\u001b[39m.\u001b[39;49m_register_wrapper_optimizer_cls(optimizer_v2\u001b[39m.\u001b[39mOptimizerV2,\n\u001b[1;32m   1181\u001b[0m                                                 LossScaleOptimizerV1)\n\u001b[1;32m   1184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_multiply_gradient\u001b[39m(gradient, scale):\n\u001b[1;32m   1185\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Multiply a (possibly sparse) gradient by the given scale factor.\"\"\"\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import preprocessing\n","from tensorflow.keras.preprocessing import image_dataset_from_directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1658842417706,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"pjqqzJcoIh-_","outputId":"5b109c85-fe97-4aff-ee95-5924660eceb7"},"outputs":[],"source":["#!git clone https://github.com/fabiopereira59/abeilles-cap500"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1046,"status":"ok","timestamp":1658842418749,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"I7Di5BLCIh-_","outputId":"7dd95317-c6ba-4442-961c-a457133d7d49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19289 files belonging to 122 classes.\n"]}],"source":["IMG_SIZE = 224\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/sets_above30/train',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1658842418750,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"VgrOKSfaIh-_","outputId":"b2d52dcc-a61e-49cd-c35b-8538f58c17bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Acasis viretata', 'Acleris holmiana', 'Acleris variegana', 'Acontia lucida', 'Agapeta hamana', 'Agapeta zoegana', 'Agrotis exclamationis', 'Agrotis puta', 'Aleimma loeflingiana', 'Anania hortulata', 'Angerona prunaria', 'Apamea crenata', 'Aphomia sociella', 'Aplocera plagiata', 'Apoda limacodes', 'Archips xylosteana', 'Arctia villica', 'Atethmia centrago', 'Biston betularia', 'Campaea margaritaria', 'Camptogramma bilineata', 'Carcina quercana', 'Celypha striana', 'Chiasmia clathrata', 'Chrysoteuchia culmella', 'Colocasia coryli', 'Cosmia trapezina', 'Crambus lathoniellus', 'Crambus pascuella', 'Craniophora ligustri', 'Cryphia algae', 'Cyclophora punctaria', 'Cydalima perspectalis', 'Dolicharthria punctalis', 'Dysgonia algira', 'Ecleora solieraria', 'Ecpyrrhorrhoe rubiginalis', 'Eilema caniola', 'Eilema complana', 'Eilema griseola', 'Eilema lurideola', 'Endotricha flammealis', 'Ennomos erosaria', 'Epiblema foenella', 'Epirrhoe alternata', 'Epirrhoe galiata', 'Eremobia ochroleuca', 'Ethmia bipunctella', 'Eublemma parva', 'Eucrostes indigenata', 'Eudonia lacustrata', 'Eudonia mercurella', 'Eupithecia centaureata', 'Euproctis chrysorrhoea', 'Euthrix potatoria', 'Euxoa obelisca', 'Evergestis forficalis', 'Falcaria lacertinaria', 'Gastropacha quercifolia', 'Habrosyne pyritoides', 'Homoeosoma sinuella', 'Hoplodrina octogenaria', 'Horisme vitalbata', 'Hypena proboscidalis', 'Hypsopygia costalis', 'Idaea aversata', 'Idaea degeneraria', 'Idaea filicata', 'Idaea fuscovenosa', 'Idaea humiliata', 'Idaea infirmaria', 'Idaea moniliata', 'Idaea ostrinaria', 'Idaea rusticata', 'Idaea subsericeata', 'Laspeyria flexula', 'Ligdia adustata', 'Lomaspilis marginata', 'Lozotaeniodes formosana', 'Lymantria dispar', 'Malacosoma neustria', 'Mesoligia furuncula', 'Mythimna albipuncta', 'Mythimna vitellina', 'Nomophila noctuella', 'Nycteola revayana', 'Ochropleura plecta', 'Oncocera semirubella', 'Orthonama obstipata', 'Ostrinia nubilalis', 'Parapoynx stratiotata', 'Pelurga comitata', 'Peribatodes rhomboidaria', 'Phycita roborella', 'Plutella xylostella', 'Pyrausta aurata', 'Pyrausta despicata', 'Pyrausta purpuralis', 'Pyrausta sanguinalis', 'Rhodometra sacraria', 'Rivula sericealis', 'Scoparia pyralella', 'Scoparia subfusca', 'Scopula ornata', 'Scopula rubiginata', 'Sitochroa verticalis', 'Sphinx ligustri', 'Spilonota ocellana', 'Stauropus fagi', 'Stegania trimaculata', 'Synaphe punctalis', 'Thalpophila matura', 'Thaumetopoea processionea', 'Thisanotia chrysonuchella', 'Thyatira batis', 'Timandra comae', 'Tortrix viridana', 'Triodia sylvina', 'Tyta luctuosa', 'Watsonalla uncinula', 'Xestia c-nigrum', 'Zeiraphera isertana']\n","122\n"]}],"source":["class_names = train_ds.class_names\n","print(class_names)\n","nb_classes = len(class_names)\n","print(nb_classes)"]},{"cell_type":"markdown","metadata":{"id":"T8wS3HAynMlY"},"source":["## Chargement des données"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1658842446314,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"FR4iw29DI1V_"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1658842446586,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"4jXjNBybI1V_"},"outputs":[],"source":["# Paramètres\n","IMG_SIZE = 224 # pour utiliser ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1658842447622,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"I_nea1RwI1V_","outputId":"8ca05ddc-6308-47e6-91c2-d82cb8ca9ebe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19289 files belonging to 122 classes.\n","Found 2393 files belonging to 122 classes.\n"]}],"source":["# Récupération des dataset pour l'entraînement (train, val)\n","# Shuffle à false pour avoir accès aux images depuis\n","# leur chemin d'accès avec train_ds.file_paths\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/sets_above30/train/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","\n","validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory='/home/lucien/projet_lepinoc/data/sets_above30/val/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))"]},{"cell_type":"markdown","metadata":{"id":"CN1hk3SeoEYJ"},"source":["## Augmentation de données : Sequence et Albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"executionInfo":{"elapsed":22321,"status":"ok","timestamp":1658842474363,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"-WvZXN580RYP","outputId":"c774cb1e-156d-48a6-e6f6-97bcc6c0b2ab"},"outputs":[],"source":["# !pip uninstall opencv-python-headless==4.5.5.62\n","# !pip install opencv-python-headless==4.1.2.30\n","# !pip install -q -U albumentations\n","# !echo \"$(pip freeze | grep albumentations) is successfully installed\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1658842520255,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"G1H0ApCB35Gn"},"outputs":[{"ename":"ValueError","evalue":"numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mimport\u001b[39;00m (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mA\u001b[39;00m\n\u001b[1;32m      4\u001b[0m AUGMENTATIONS_TRAIN \u001b[39m=\u001b[39m Compose([\n\u001b[1;32m      5\u001b[0m     Rotate(limit\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m100\u001b[39m], p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[1;32m      6\u001b[0m     HorizontalFlip(p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     RandomBrightnessContrast(p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     10\u001b[0m ])\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/albumentations/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1.3.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/albumentations/augmentations/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Common classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mblur\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mblur\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcrops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/albumentations/augmentations/blur/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/albumentations/augmentations/blur/functional.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m convolve\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m scale\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _maybe_process_in_chunks,\n\u001b[1;32m     12\u001b[0m     clipped,\n\u001b[1;32m     13\u001b[0m     preserve_shape,\n\u001b[1;32m     14\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/albumentations/augmentations/functional.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mimport\u001b[39;00m random_utils\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     MAX_VALUES_BY_DTYPE,\n\u001b[1;32m     13\u001b[0m     _maybe_process_in_chunks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     preserve_shape,\n\u001b[1;32m     22\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/skimage/__init__.py:122\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# We are not importing the rest of the scikit during the build\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shared\u001b[39;00m \u001b[39mimport\u001b[39;00m geometry\n\u001b[1;32m    123\u001b[0m         \u001b[39mdel\u001b[39;00m geometry\n\u001b[1;32m    124\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32mgeometry.pyx:1\u001b[0m, in \u001b[0;36minit skimage._shared.geometry\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"]}],"source":["from albumentations import (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n","import albumentations as A\n","\n","AUGMENTATIONS_TRAIN = Compose([\n","    Rotate(limit=[0,100], p=0.5),\n","    HorizontalFlip(p=0.5),\n","    VerticalFlip(p=0.5),\n","    Affine(shear=[-45, 45], p=0.5),\n","    RandomBrightnessContrast(p=0.5)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1658842630318,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tEaycO8VhyLH"},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import cv2 as cv\n","\n","class AbeillesSequence(Sequence):\n","    # Initialisation de la séquence avec différents paramètres\n","    def __init__(self, x_train, y_train, batch_size, augmentations):\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.classes = class_names\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.indices1 = np.arange(len(x_train))\n","        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n","        # aux données et sont randomisés à chaque epoch pour varier la composition\n","        # des batches au cours de l'entraînement\n","\n","    # Fonction calculant le nombre de pas de descente du gradient par epoch\n","    def __len__(self):\n","        return int(np.ceil(self.x_train.shape[0] / float(self.batch_size)))\n","    \n","    # Application de l'augmentation de données à chaque image du batch\n","    def apply_augmentation(self, bx, by):\n","\n","        batch_x = np.zeros((bx.shape[0], IMG_SIZE, IMG_SIZE, 3))\n","        batch_y = by\n","        \n","        # Pour chaque image du batch\n","        for i in range(len(bx)):\n","            class_labels = []\n","            class_id = np.argmax(by[i])\n","            class_labels.append(self.classes[class_id])\n","\n","            # Application de l'augmentation à l'image\n","            img = cv.imread(bx[i])\n","            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","            transformed = self.augment(image=img)\n","            #on veut changer la taille de transformed['image'] en (224,224,3)\n","            transformed_image = transformed['image'].copy()\n","            transformed_image.resize((IMG_SIZE, IMG_SIZE, 3))\n","\n","            batch_x[i] = transformed_image\n","      \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n","    # idx = position du batch (idx = 5 => on prend le 5ème batch)\n","    def __getitem__(self, idx):\n","        batch_x = self.x_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","        batch_y = self.y_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","           \n","        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n","\n","        # Normalisation des données\n","        batch_x = tf.keras.applications.resnet.preprocess_input(batch_x)\n","        \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12892,"status":"ok","timestamp":1658842645801,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MQxHTeedPwsn"},"outputs":[{"name":"stdout","output_type":"stream","text":["122\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-28 12:44:22.615300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [19289]\n","\t [[{{node Placeholder/_4}}]]\n","2023-04-28 12:44:22.615604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [19289]\n","\t [[{{node Placeholder/_4}}]]\n"]}],"source":["# Les images sont stockées avec les chemins d'accès\n","import numpy as np\n","print(nb_classes)\n","\n","x_train = np.array(train_ds.file_paths)\n","y_train = np.zeros((19289, nb_classes))#rentrer la taille du train: 19789\n","\n","ind_data = 0\n","for bx, by in train_ds.as_numpy_iterator():\n","  y_train[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3795,"status":"ok","timestamp":1658842649588,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"qclVcaJrG1Gn"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-04-28 12:44:28.819143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2393]\n","\t [[{{node Placeholder/_0}}]]\n","2023-04-28 12:44:28.819638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2393]\n","\t [[{{node Placeholder/_0}}]]\n"]}],"source":["# Instanciation de la Sequence\n","train_ds_aug = AbeillesSequence(x_train, y_train, batch_size=16, augmentations=AUGMENTATIONS_TRAIN)\n","\n","# Normalisation des données de validation\n","import numpy as np\n","import tensorflow as tf\n","\n","x_val = np.zeros((2393, IMG_SIZE, IMG_SIZE, 3))#rentrer la taille du valval\n","y_val = np.zeros((2393, nb_classes))#rentrer la taille du val\n","\n","ind_data = 0\n","for bx, by in validation_ds.as_numpy_iterator():\n","  x_val[ind_data:ind_data+bx.shape[0]] = bx\n","  y_val[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]\n","\n","x_val = tf.keras.applications.resnet.preprocess_input(x_val)"]},{"cell_type":"markdown","metadata":{"id":"h6MijFSSqNEi"},"source":["## Création du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1658842655320,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"vw8pjRnlGcOW"},"outputs":[],"source":["from tensorflow.keras import regularizers\n","from tensorflow.keras import optimizers\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"wHrwHiS3Szq3"},"source":["### Poids d'imagenet"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4453,"status":"ok","timestamp":1658842661739,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"cVEsReLqsmGX"},"outputs":[],"source":["conv_base = keras.applications.resnet.ResNet101(\n","    include_top=False,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    pooling=None,\n","    classes=nb_classes,\n",")\n","\n","model = keras.Sequential(\n","    [\n","        conv_base,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1658842661740,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"8Ouz5O07S8q3","outputId":"b8c82afd-4776-4006-fe62-07a652e7bfde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 122)               249978    \n","                                                                 \n","=================================================================\n","Total params: 42,908,154\n","Trainable params: 42,802,810\n","Non-trainable params: 105,344\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"34MnJ8YHqXKC"},"source":["### Poids INat2021"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5731,"status":"ok","timestamp":1658475118412,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"LR4GIHqVqXKC","outputId":"984ac58b-baa3-4228-876f-42bfb539af62"},"outputs":[],"source":["# from tensorflow import keras\n","# conv_base = keras.models.load_model('drive/MyDrive/Stage2A/INat2021/2623871_resnet50_simclr_v1_inat20_no_top.h5')\n","\n","# model = keras.Sequential(\n","#     [\n","#         conv_base,\n","#         layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","#     ]\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1658475126907,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"w5wZDTlHqXKD","outputId":"bc14d7c3-074d-45d0-b798-bd78536f4ab1"},"outputs":[],"source":["# model.summary()"]},{"cell_type":"markdown","metadata":{"id":"HYD4k8GDtG-G"},"source":["## Hierarchical loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":852,"status":"ok","timestamp":1658842675647,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"vHFsiNjctJsM"},"outputs":[{"name":"stdout","output_type":"stream","text":["nb species:  122\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","hierarchie = pd.read_csv(\"/home/lucien/projet_lepinoc/lepinoc-detection/classif/convert_and_analyse_data/correct_list.csv\", delimiter = ';')\n","\n","species = hierarchie[\"Espece\"].unique()\n","nb_species = len(species)\n","\n","genus = list(hierarchie[\"Genre\"].unique())\n","nb_genus = len(genus)\n","\n","family = list(hierarchie[\"Famille\"].unique())\n","nb_family = len(family)\n","\n","subfamily = list(hierarchie[\"Sous-Famille\"].unique())\n","nb_subfamily = len(subfamily)\n","\n","#hierarchie.set_index(\"species\", inplace=True)\n","data = pd.read_csv(\"/home/lucien/projet_lepinoc/lepinoc-detection/classif/convert_and_analyse_data/especes.csv\")\n","#data.set_index(\"species\", inplace=True)\n","\n","species_to_genus = np.zeros((nb_genus, nb_species))\n","genus_to_subfamily = np.zeros((nb_subfamily, nb_genus))\n","subfamily_to_family = np.zeros((nb_family, nb_subfamily))\n","print(\"nb species: \", nb_species)\n","for i in range(nb_species):\n","  print(i)\n","  nb_images = data.at[i, \"0\"]\n","  # species -> genus\n","  genus_species = hierarchie.at[i, \"Genre\"]\n","  ind_genus = genus.index(genus_species)\n","  species_to_genus[ind_genus, i] = 1\n","\n","  # genus -> subfamily\n","  subfamily_species = hierarchie.at[i, \"Sous-Famille\"]\n","  ind_subfamily = subfamily.index(subfamily_species)\n","  genus_to_subfamily[ind_subfamily, ind_genus] = 1\n","\n","  # subfamily -> family\n","  family_species = hierarchie.at[i, \"Famille\"]\n","  ind_family = family.index(family_species)\n","  subfamily_to_family[ind_family, ind_subfamily] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658842675648,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tAmdf0ELtSUr"},"outputs":[],"source":["from numpy.ma.core import transpose\n","from keras import backend as K\n","import math\n","import tensorflow as tf\n","\n","# Définition de la fonction de perte\n","def Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size, alpha=0.1):\n","\n","    def weight(height=1):\n","      return math.exp(-alpha * height)\n","    \n","    def species_loss(y_true, y_pred):\n","      height = 0\n","      return weight(height) * K.categorical_crossentropy(y_true, y_pred)\n","  \n","    def species_to_genus_loss(y_true, y_pred):\n","      height = 1\n","      y_true_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_true, tf.float64), transpose_b=True))\n","      y_pred_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_pred, tf.float64), transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_genus, y_pred_genus), y_true_genus, y_pred_genus\n","    \n","    def genus_to_subfamily_loss(y_true, y_pred):\n","      height = 2\n","      y_true_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_true, transpose_b=True))\n","      y_pred_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_subfamily, y_pred_subfamily), y_true_subfamily, y_pred_subfamily\n","    \n","    def subfamily_to_family_loss(y_true, y_pred):\n","      height = 3\n","      y_true_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_true, transpose_b=True))\n","      y_pred_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_family, y_pred_family)\n","\n","    def HIERARCHICAL_loss(y_true, y_pred):\n","      loss_species = tf.cast(species_loss(y_true, y_pred), tf.float64)\n","      loss_genus, y_true_genus, y_pred_genus = species_to_genus_loss(y_true, y_pred)\n","      loss_subfamily, y_true_subfamily, y_pred_subfamily = genus_to_subfamily_loss(y_true_genus, y_pred_genus)\n","      loss_family = subfamily_to_family_loss(y_true_subfamily, y_pred_subfamily)\n","      return (loss_species + loss_genus + loss_subfamily + loss_family)/batch_size\n","   \n","    # Return a function\n","    return HIERARCHICAL_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658842675649,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MEDUO4smtiAS"},"outputs":[],"source":["loss=[Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size=16, alpha=0.5)]"]},{"cell_type":"markdown","metadata":{"id":"AGrRfh4ZrHM1"},"source":["## Entraînement du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1658842682265,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"IOxq6KpzGb9I"},"outputs":[],"source":["# Ajout de l'optimiseur, de la fonction coût et des métriques\n","lr = 1e-3\n","model.compile(optimizers.SGD(learning_rate=lr, momentum=0.9), loss=loss, metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658842683474,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tWhbz7V0Gtjs"},"outputs":[],"source":["# Les callbacks, là où on sauvegarde les poids du réseau\n","\n","#filepath = path to save the model at the end of each epoch\n","\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/home/lucien/projet_lepinoc/lepinoc-detection/classif/convert_and_analyse_data/model_crop/model_crop', \n","    save_weights_only=True,\n","    monitor='val_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1)\n","\n","#early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","#    monitor=\"val_categorical_accuracy\",\n","#    min_delta=0.01,\n","#    patience=8,\n","#    verbose=1,\n","#    mode=\"auto\")\n","reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1,\n","                              patience=5, min_lr=0.00001, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":129103,"status":"error","timestamp":1658842814895,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"0hxLaoBeGxTn","outputId":"c04250de-bd71-4292-8434-629bf8ae1fa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/80\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-28 12:45:41.807121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n","\t [[{{node Placeholder/_0}}]]\n","2023-04-28 12:45:42.004497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n","2023-04-28 12:45:42.006467: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1068 : UNIMPLEMENTED: DNN library is not found.\n","2023-04-28 12:45:42.006547: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n","\t [[{{node sequential/resnet101/conv1_conv/Conv2D}}]]\n"]},{"ename":"UnimplementedError","evalue":"Graph execution error:\n\nDetected at node 'sequential/resnet101/conv1_conv/Conv2D' defined at (most recent call last):\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_80121/980968933.py\", line 1, in <module>\n      history = model.fit(train_ds_aug, epochs=80, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb]) #nbre d'epoch de fabio:150\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/resnet101/conv1_conv/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/resnet101/conv1_conv/Conv2D}}]] [Op:__inference_train_function_36489]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds_aug, epochs\u001b[39m=\u001b[39;49m\u001b[39m80\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (x_val, y_val), callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_cb, reduce_lr_cb]) \u001b[39m#nbre d'epoch de fabio:150\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/resnet101/conv1_conv/Conv2D' defined at (most recent call last):\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_80121/980968933.py\", line 1, in <module>\n      history = model.fit(train_ds_aug, epochs=80, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb]) #nbre d'epoch de fabio:150\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/lucien/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/resnet101/conv1_conv/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/resnet101/conv1_conv/Conv2D}}]] [Op:__inference_train_function_36489]"]}],"source":["history = model.fit(train_ds_aug, epochs=80, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb]) #nbre d'epoch de fabio:150"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cuda version : 12.0\n","cudnn=8.1.0\n","tensorflow: 2.12.0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(tf\u001b[39m.\u001b[39m__version__)\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/__init__.py:476\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    475\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m    477\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[39mpass\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n","File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/mixed_precision/loss_scale_optimizer.py:1180\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39m_create_or_restore_slot_variable(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m         slot_variable_position, slot_name, variable)\n\u001b[1;32m   1179\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1180\u001b[0m mixed_precision\u001b[39m.\u001b[39;49m_register_wrapper_optimizer_cls(optimizer_v2\u001b[39m.\u001b[39mOptimizerV2,\n\u001b[1;32m   1181\u001b[0m                                                 LossScaleOptimizerV1)\n\u001b[1;32m   1184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_multiply_gradient\u001b[39m(gradient, scale):\n\u001b[1;32m   1185\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Multiply a (possibly sparse) gradient by the given scale factor.\"\"\"\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","import numpy as np\n","print(np.__version__)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWAJ28hjh3VB4RHipSfk+k","collapsed_sections":["xzZYwhV0Iaww","T8wS3HAynMlY","CN1hk3SeoEYJ","h6MijFSSqNEi","wHrwHiS3Szq3","34MnJ8YHqXKC","HYD4k8GDtG-G","AGrRfh4ZrHM1"],"name":"ClassifAbeilles.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
